{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This lab on K-Nearest Neighbors is a python adaptation of p. 163-167 of \"Introduction to Statistical Learning with Applications in R\" by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani. Originally adapted by Jordi Warmenhoven (github.com/JWarmenhoven/ISLR-python), modified by R. Jordan Crouser at Smith College for SDS293: Machine Learning (Spring 2016)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# K-Nearest Neighbors\n",
    "In this lab, we will perform KNN clustering on the Smarket dataset from ISLR. This data set consists of percentage returns for the S&P 500 stock index over 1,250 days, from the beginning of 2001 until the end of 2005.\n",
    "\n",
    "For each date, we have recorded the percentage returns for each of the five previous trading days (Lag1 through Lag5).\n",
    "\n",
    "We have also recorded:\n",
    "\n",
    "Volume (the number of shares traded on the previous day, in billions)\n",
    "Today (the percentage return on the date in question)\n",
    "Direction (whether the market was Up or Down on this date).\n",
    "We can use the head() function to look at the first few rows:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\212628255\\AppData\\Local\\Temp\\ipykernel_40084\\3351311709.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv('Smarket.csv', index_col=0, parse_dates = True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Year   Lag1   Lag2   Lag3   Lag4   Lag5  Volume  Today Direction\n1  2001  0.381 -0.192 -2.624 -1.055  5.010  1.1913  0.959        Up\n2  2001  0.959  0.381 -0.192 -2.624 -1.055  1.2965  1.032        Up\n3  2001  1.032  0.959  0.381 -0.192 -2.624  1.4112 -0.623      Down\n4  2001 -0.623  1.032  0.959  0.381 -0.192  1.2760  0.614        Up\n5  2001  0.614 -0.623  1.032  0.959  0.381  1.2057  0.213        Up",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Lag1</th>\n      <th>Lag2</th>\n      <th>Lag3</th>\n      <th>Lag4</th>\n      <th>Lag5</th>\n      <th>Volume</th>\n      <th>Today</th>\n      <th>Direction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>2001</td>\n      <td>0.381</td>\n      <td>-0.192</td>\n      <td>-2.624</td>\n      <td>-1.055</td>\n      <td>5.010</td>\n      <td>1.1913</td>\n      <td>0.959</td>\n      <td>Up</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2001</td>\n      <td>0.959</td>\n      <td>0.381</td>\n      <td>-0.192</td>\n      <td>-2.624</td>\n      <td>-1.055</td>\n      <td>1.2965</td>\n      <td>1.032</td>\n      <td>Up</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2001</td>\n      <td>1.032</td>\n      <td>0.959</td>\n      <td>0.381</td>\n      <td>-0.192</td>\n      <td>-2.624</td>\n      <td>1.4112</td>\n      <td>-0.623</td>\n      <td>Down</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2001</td>\n      <td>-0.623</td>\n      <td>1.032</td>\n      <td>0.959</td>\n      <td>0.381</td>\n      <td>-0.192</td>\n      <td>1.2760</td>\n      <td>0.614</td>\n      <td>Up</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2001</td>\n      <td>0.614</td>\n      <td>-0.623</td>\n      <td>1.032</td>\n      <td>0.959</td>\n      <td>0.381</td>\n      <td>1.2057</td>\n      <td>0.213</td>\n      <td>Up</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Smarket_lab.csv', index_col=0, parse_dates = True)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Today we're going to try to predict Direction using percentage returns from the previous two days (Lag1 and Lag2). We'll build our model using the KNeighborsClassifier() function, which is part of the neighbors submodule of SciKitLearn (sklearn). We'll also grab a couple of useful tools from the metrics submodule:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This function works rather differently from the other model-fitting functions that we have encountered thus far. Rather than a two-step approach in which we first fit the model and then we use the model to make predictions, knn() forms predictions using a single command. The function requires four inputs.\n",
    "\n",
    "- A matrix containing the predictors associated with the training data, labeled X_train below.\n",
    "- A matrix containing the predictors associated with the test data, labeled X_test below.\n",
    "- A vector containing the class labels for the training observations, labeled Y_train below.\n",
    "- A value for K, the number of nearest neighbors to be used by the classifier.\n",
    "\n",
    "We'll first create a vector corresponding to the observations from 2001 through 2004, which we'll use to train the model. We will then use this vector to create a held out data set of observations from 2005 on which we will test. We'll also pull out our training and test labels."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# X_train = df[:2004][['Lag1','Lag2']]\n",
    "# y_train = df[:2004]['Direction']\n",
    "#\n",
    "# X_test = df[2004:][['Lag1','Lag2']]\n",
    "# y_test = df[2004:]['Direction']\n",
    "\n",
    "X_train = df[['Lag1', 'Lag2']].loc[df.Year < 2005]\n",
    "y_train = df['Direction'].loc[df.Year < 2005]\n",
    "\n",
    "X_test = df[['Lag1', 'Lag2']].loc[df.Year > 2004]\n",
    "y_test = df['Direction'].loc[df.Year > 2004]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now the neighbors.KNeighborsClassifier() function can be used to predict the marketâ€™s movement for the dates in 2005."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors = 1)\n",
    "pred = knn.fit(X_train, y_train).predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The confusion_matrix() function can be used to produce a confusion matrix in order to determine how many observations were correctly or incorrectly classified. The classification_report() function gives us some summary statistics on the classifier's performance:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43 58]\n",
      " [68 83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down      0.426     0.387     0.406       111\n",
      "          Up      0.550     0.589     0.568       141\n",
      "\n",
      "    accuracy                          0.500       252\n",
      "   macro avg      0.488     0.488     0.487       252\n",
      "weighted avg      0.495     0.500     0.497       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, pred).T)\n",
    "print(classification_report(y_test, pred, digits=3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The results using  K=1\n",
    "  are not very good, since only 50% of the observations are correctly predicted. Of course, it may be that  K=1\n",
    "  results in an overly flexible fit to the data. Below, we repeat the analysis using  K=3."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48 55]\n",
      " [63 86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down      0.466     0.432     0.449       111\n",
      "          Up      0.577     0.610     0.593       141\n",
      "\n",
      "    accuracy                          0.532       252\n",
      "   macro avg      0.522     0.521     0.521       252\n",
      "weighted avg      0.528     0.532     0.529       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, pred).T)\n",
    "print(classification_report(y_test, pred, digits=3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 1\n",
      "[[43 58]\n",
      " [68 83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down      0.426     0.387     0.406       111\n",
      "          Up      0.550     0.589     0.568       141\n",
      "\n",
      "    accuracy                          0.500       252\n",
      "   macro avg      0.488     0.488     0.487       252\n",
      "weighted avg      0.495     0.500     0.497       252\n",
      "\n",
      "K = 2\n",
      "[[74 93]\n",
      " [37 48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down      0.443     0.667     0.532       111\n",
      "          Up      0.565     0.340     0.425       141\n",
      "\n",
      "    accuracy                          0.484       252\n",
      "   macro avg      0.504     0.504     0.479       252\n",
      "weighted avg      0.511     0.484     0.472       252\n",
      "\n",
      "K = 3\n",
      "[[48 55]\n",
      " [63 86]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down      0.466     0.432     0.449       111\n",
      "          Up      0.577     0.610     0.593       141\n",
      "\n",
      "    accuracy                          0.532       252\n",
      "   macro avg      0.522     0.521     0.521       252\n",
      "weighted avg      0.528     0.532     0.529       252\n",
      "\n",
      "K = 4\n",
      "[[71 82]\n",
      " [40 59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down      0.464     0.640     0.538       111\n",
      "          Up      0.596     0.418     0.492       141\n",
      "\n",
      "    accuracy                          0.516       252\n",
      "   macro avg      0.530     0.529     0.515       252\n",
      "weighted avg      0.538     0.516     0.512       252\n",
      "\n",
      "K = 5\n",
      "[[40 59]\n",
      " [71 82]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down      0.404     0.360     0.381       111\n",
      "          Up      0.536     0.582     0.558       141\n",
      "\n",
      "    accuracy                          0.484       252\n",
      "   macro avg      0.470     0.471     0.469       252\n",
      "weighted avg      0.478     0.484     0.480       252\n",
      "\n",
      "K = 6\n",
      "[[63 79]\n",
      " [48 62]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down      0.444     0.568     0.498       111\n",
      "          Up      0.564     0.440     0.494       141\n",
      "\n",
      "    accuracy                          0.496       252\n",
      "   macro avg      0.504     0.504     0.496       252\n",
      "weighted avg      0.511     0.496     0.496       252\n",
      "\n",
      "K = 7\n",
      "[[41 65]\n",
      " [70 76]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down      0.387     0.369     0.378       111\n",
      "          Up      0.521     0.539     0.530       141\n",
      "\n",
      "    accuracy                          0.464       252\n",
      "   macro avg      0.454     0.454     0.454       252\n",
      "weighted avg      0.462     0.464     0.463       252\n",
      "\n",
      "K = 8\n",
      "[[63 82]\n",
      " [48 59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down      0.434     0.568     0.492       111\n",
      "          Up      0.551     0.418     0.476       141\n",
      "\n",
      "    accuracy                          0.484       252\n",
      "   macro avg      0.493     0.493     0.484       252\n",
      "weighted avg      0.500     0.484     0.483       252\n",
      "\n",
      "K = 9\n",
      "[[45 61]\n",
      " [66 80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Down      0.425     0.405     0.415       111\n",
      "          Up      0.548     0.567     0.557       141\n",
      "\n",
      "    accuracy                          0.496       252\n",
      "   macro avg      0.486     0.486     0.486       252\n",
      "weighted avg      0.494     0.496     0.495       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(1,10):\n",
    "    print(f\"K = {k}\")\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "    print(confusion_matrix(y_test, pred).T)\n",
    "    print(classification_report(y_test, pred, digits=3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### It looks like for classifying this dataset, KNN might not be the right approach."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
